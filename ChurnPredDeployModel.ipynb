{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc3a139-99ac-46a5-8360-1876252bee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93018836-3cc3-401a-b749-ba5e47d6ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/conda/envs/myenv/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/myenv/lib/python3.11/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/myenv/lib/python3.11/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/myenv/lib/python3.11/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/myenv/lib/python3.11/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/myenv/lib/python3.11/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/myenv/lib/python3.11/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/myenv/lib/python3.11/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/myenv/lib/python3.11/site-packages (from requests->kagglehub) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation, read the csv file, make the column names more homogenous, and deal with categorical and numerical values.\n",
    "\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "311e93dc-f233-4c7e-a4a5-a2da95ec9bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/blastchar/telco-customer-churn/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"blastchar/telco-customer-churn\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e638d561-2dcc-4b12-8a54-2ba533ed761f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Build full path to the CSV file\n",
    "csv_file = os.path.join(\n",
    "    \"/home/codespace/.cache/kagglehub/datasets/blastchar/telco-customer-churn/versions/1\",\n",
    "    \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    ")\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4d935c-426d-42ae-a60a-37bc62df90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    " \n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    " \n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    " \n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    " \n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    " \n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e3fc6d-fb76-4d13-ab1d-93d4f79b075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting. We use the train_test_split function to divide the dataset in full_train and test data.\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d2252c-25c5-4751-a8e2-7a2fc23eda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    " \n",
    "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "       'phoneservice', 'multiplelines', 'internetservice',\n",
    "       'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',\n",
    "       'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',\n",
    "       'paymentmethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65149a2-37dc-40dd-9954-598e3ce73a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function. It has three arguments – the training dataframe and the target values y_train, and the third argument is C which is a \n",
    "# LogisticRegression parameter for our model.\n",
    "# First step here is to create dictionaries from the categorical columns, the numerical columns are ignored here. \n",
    "# Next we create a DictVectorizer instance which we need to use fit_transform function on the dictionaries. \n",
    "# So we get the X_train. Then we create our model which is a logistic regression model, that we can use for training (fit function) based on \n",
    "# the training data (X_train and y_train). To apply the model later we need to return the DictVectorizer and the model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4651aa35-cddc-46cd-81f7-4883cf0d50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    " \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    " \n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    " \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b23071-eaea-44f3-bcc8-7407959f35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need also the DictVectorizer. Both predict function. Besides both arguments we also need a dataframe where we can provide a prediction for.\n",
    "# First step here is the same like in training function, we need to get the dictionaries. \n",
    "# This can be transformed by the DictVectorizer so we get the X, what we need to make a prediction on.\n",
    "# What we return here is the predicted probability for churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891821c9-8b14-4424-acd7-1dba41412bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "     dicts = df[categorical + numerical].to_dict(orient='records')\n",
    " \n",
    "     X = dv.transform(dicts)\n",
    "     y_pred = model.predict_proba(X)[:,1]\n",
    " \n",
    "     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ba2bf8-4376-4b20-ae05-05c34f321782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setup two parameters. The first one is the C value for the Logistic Regression model, and the ‘n_splits’ parameter tells us how many splits \n",
    "# we’re going to use in K-Fold cross-validation. Here, we’re using 5 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "491e2000-c55d-4a57-8ab9-c1306b628857",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "186cbbed-91c6-4b6b-aab2-35fe62d91bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement K-Fold cross validation, where we use the parameters from the last code. The for loop loops over all folds and does a training for each. \n",
    "# After that we calculate the roc_auc_score and collect the values for each fold. \n",
    "# At the end the mean score and the standard deviation for all folds are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b96c144-501f-44e0-b52a-afc8bff4bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.842 +- 0.007\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)  \n",
    " \n",
    "scores = []\n",
    " \n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    " \n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    " \n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    " \n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    " \n",
    "print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d407bc09-71b7-4303-af20-19fe67a98923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.844596557056621,\n",
       " 0.845183998808105,\n",
       " 0.83332129239414,\n",
       " 0.8347609036260153,\n",
       " 0.8517147249850961]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a841988-0fbc-4744-8961-a779f8a0a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last step is to train the final model based on the full_train data. The steps here are similar to the steps mentioned before. \n",
    "# First is model training, then predicting the test data, and lastly calculate the roc_auc_score. \n",
    "# We see a value of 85.7% which is a bit higher than the average of the k-folds. But there is not a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a012db82-000f-4a2a-bda1-c986c1d3341b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583463334308341"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "y_test = df_test.churn.values\n",
    " \n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a89b0ea-ed5e-4e49-b2bc-1d6945daf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cabc7a68-6808-4c11-b7f3-2dc6606dfa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa00b8-939d-4494-a71e-7d20d6c17b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to name our model file before we can write it to a file. The following code demonstrates two ways of naming the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf63c4b2-d31d-4815-abf3-35f3633bd6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = 'model_C=%s.bin' % C\n",
    "output_file\n",
    "# Output: 'model_C=1.0.bin'\n",
    " \n",
    "output_file = f'model_C={C}.bin'\n",
    "output_file\n",
    "# Output: 'model_C=1.0.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bcfce7d-fb41-4015-81db-d8106489edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to create a file with that file name. ‘wb’ means Write Binary. \n",
    "# We need to save DictVectorizer and the model as well, because with just the model we’ll not be able to translate a customer into a feature matrix.\n",
    "# Closing the file is crucial. Otherwise, we cannot be certain whether this file truly contains the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12b32655-26a7-4d30-b722-e3f236843368",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open(output_file, 'wb')\n",
    " \n",
    "pickle.dump((dv, model), f_out)\n",
    " \n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "737d0075-064a-4521-81ca-cc345d81120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid accidentally forgetting to close the file, we can use the ‘with’ statement, which ensures that the file is closed automatically. \n",
    "# Everything we do inside the ‘with’ statement keeps the file open. However, once we exit this statement, the file is automatically closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "660048d4-66df-4012-b519-2fc30c6f8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump((dv, model), f_out)\n",
    "    #do staff\n",
    "\n",
    "#do other staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5cee7e5-d632-4bca-a2cb-986ceca25431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87fcaf1c-8f9c-4ca6-9ed3-2185b376e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click restart the Kernal to start the process again without previouse variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586f66de-d9c4-4439-bf46-c585e2f34ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0778fe-671a-4ee5-9a6b-c918260ff885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model_C=1.0.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b2a1cd-781b-4e83-b659-4cbedeb2bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rb' - mens open the file for reading, if we leave 'wb' it will overwrite the file\n",
    "with open(model_file, 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75482260-ffb9-4f21-a56f-c13fec428a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8787ef91-79c3-4b72-ab2f-c40942c12e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading the model, let’s use it to score one sample customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ae0510-0840-4215-815d-4d7b3a890366",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef504435-d0d8-48d3-a528-27d111a1bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we can apply the predict function to this customer we need to turn it into a feature matrix. \n",
    "# The DictVectorizer expects a list of dictionaries, that’s why we create a list with one customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aa31b00-b403-48d4-bf63-42e2c135b344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  , 29.85,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  , 29.85]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dv.transform([customer])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6415e991-61ae-4bbd-9f81-5fc5625a71c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37250474, 0.62749526]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use predict function to get the probability that this particular customer is going to churn. \n",
    "# We’re interested in the second element, so we need to set the row=0 and column=1.\n",
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b363f673-5a5e-49e6-8660-1eb0a14802b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6274952584954934)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c566f1b8-568a-4b8b-a1fd-fe3daec5d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download thie file\n",
    "# Turning our notebook into a Python script\n",
    "# We can turn the Jupyter Notebook code into a Python file. One easy way of doing this is click on “File” -> “Download as” and then “Python (.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145b67d-0540-46aa-a397-6da300e0e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
