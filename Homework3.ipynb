{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff21b192-8463-4e82-97d4-f7069161fec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-10 16:47:50--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-10-10 16:47:50 (10.4 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac7bed3-7a2b-418a-b6bb-ad44ada5b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5beecd9-a899-4f1e-82ba-0030d9730023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d458a388-6282-4743-a078-6fce9e1d287a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed4820c7-2fec-4974-91e4-c043ea08367b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc3ab13-6abd-4c88-87d4-814a225c883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- df.info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1334 non-null   object \n",
      " 1   industry                  1328 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1281 non-null   float64\n",
      " 4   employment_status         1362 non-null   object \n",
      " 5   location                  1399 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n",
      "\n",
      "columns: ['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income', 'employment_status', 'location', 'interaction_count', 'lead_score', 'converted']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- df.info() ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\ncolumns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2964d9-2d98-4e41-b702-f7de00d140ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n",
      "Categorical: ['lead_source', 'industry', 'employment_status', 'location']\n"
     ]
    }
   ],
   "source": [
    "# Separate numerical and categorical \n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numerical:\", list(num_cols))\n",
    "print(\"Categorical:\", list(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "903c0af4-2fff-4844-bc09-97235692bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "df[num_cols] = df[num_cols].fillna(0.0)\n",
    "df[cat_cols] = df[cat_cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52eea68-fede-4ce0-9aa4-4efd74efa041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that everything is filled\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0154dacb-02e6-4b7e-9b1e-a1c08f35391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "converted\n",
       "1    905\n",
       "0    557\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['converted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac195403-3dde-4853-82ab-0130dd148c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1 — Most frequent value (mode) for industry\n",
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "246e7cda-9645-4312-8259-b0a4e25a52b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.435914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.053131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.374573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>0.435914</td>\n",
       "      <td>0.053131</td>\n",
       "      <td>0.374573</td>\n",
       "      <td>0.193673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "converted                                 0.435914       0.053131   \n",
       "\n",
       "                          interaction_count  lead_score  converted  \n",
       "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
       "annual_income                      0.027036    0.015610   0.053131  \n",
       "interaction_count                  1.000000    0.009888   0.374573  \n",
       "lead_score                         0.009888    1.000000   0.193673  \n",
       "converted                          0.374573    0.193673   1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2 — Correlation matrix\n",
    "# df.corr() → builds a correlation matrix — it checks how close the relationship is between every pair of number columns.\n",
    "# +1 means “move together exactly the same way.” ; -1 means “opposite directions.” ; 0 means “no connection.”\n",
    "# numeric_only=True → ignore text columns, only use numbers.\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c32c8b2-8cb9-4374-90e6-43b57d87b05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_count vs lead_score: 0.010\n",
      "number_of_courses_viewed vs lead_score: -0.005\n",
      "number_of_courses_viewed vs interaction_count: -0.024\n",
      "annual_income vs interaction_count: 0.027\n"
     ]
    }
   ],
   "source": [
    "# Compare pairs listed in the question:\n",
    "# Correlation shows how two number columns move together.\n",
    "# Positive (close to 1) → when one goes up, the other also goes up.\n",
    "# Negative (close to -1) → when one goes up, the other goes down.\n",
    "# Closer to 0 → almost no relationship.\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "for a, b in pairs:\n",
    "    print(f\"{a} vs {b}: {corr.loc[a, b]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd8f68b0-a9a4-47e1-b96a-a03107e1cc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 9), (293, 9), (293, 9))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3 — Split data in train/val/test sets with 60%/20%/20% distribution\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd2ca770-54a7-403f-9c3d-ff974d9c42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the target value y is not in your dataframe.\n",
    "y_train = df_train['converted'].values\n",
    "y_val = df_val['converted'].values\n",
    "y_test = df_test['converted'].values\n",
    "\n",
    "X_train = df_train.drop(columns=['converted'])\n",
    "X_val = df_val.drop(columns=['converted'])\n",
    "X_test = df_test.drop(columns=['converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a354f027-9f93-4335-8015-c5f4991d6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.04\n",
       "employment_status    0.01\n",
       "industry             0.01\n",
       "location             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3. Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "# Round the scores to 2 decimals using round(score, 2). Which of these variables has the biggest mutual information score?\n",
    "\n",
    "# Choose our categorical columns. Turn text into numbers (.cat.codes), because computers don’t understand words.\n",
    "# mutual_info_classif() → measures how much knowing that feature helps guess converted. We make a Series to print the scores neatly\n",
    "\n",
    "# Mutual information (MI) as a measure of how much a variable tells us about the target (y = has the client signed up or not).\n",
    "# High MI → the feature is useful for predicting y.\n",
    "#Low MI → the feature doesn’t help much.\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "cat = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "# Convert each categorical column to category codes\n",
    "X_train_cat = X_train[cat].copy()\n",
    "for col in cat:\n",
    "    X_train_cat[col] = X_train_cat[col].astype('category').cat.codes\n",
    "\n",
    "# Now calculate mutual information\n",
    "mi = mutual_info_classif(X_train_cat, y_train, discrete_features=True)\n",
    "\n",
    "# Put results in a Series, sort, and round\n",
    "mi_scores = pd.Series(mi, index=cat).sort_values(ascending=False)\n",
    "mi_scores = mi_scores.round(2)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e02bdd49-6a2e-48ea-a902-f6e81aebd00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4. Now let's train a logistic regression.\n",
    "# Remember that we have several categorical variables in the dataset. Include them using one-hot encoding. Fit the model on the training dataset.\n",
    "# To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "# model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42) Calculate the accuracy on the validation dataset \n",
    "# and round it to 2 decimal digits.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# combine categorical and numerical\n",
    "dicts_train = X_train.to_dict(orient='records')\n",
    "dicts_val = X_val.to_dict(orient='records')\n",
    "\n",
    "# DictVectorizer changes text into 0s and 1s (for example: industry=tech → column “industry_tech”=1).\n",
    "# Now X_train_encoded is all numeric and ready for the model.\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_encoded = dv.fit_transform(dicts_train)\n",
    "X_val_encoded = dv.transform(dicts_val)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val_encoded)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "round(acc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeb6f536-91fa-4107-9b22-670856a99bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy: 0.6996587030716723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'industry': 0.0,\n",
       " 'employment_status': 0.0034129692832763903,\n",
       " 'lead_score': -0.0068259385665528916}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 5. Let's find the least useful feature using the feature elimination technique.\n",
    "# Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "# Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "# For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "# Which of following feature has the smallest difference?\n",
    "\n",
    "# If the difference is small or zero, removing that feature didn’t affect accuracy much → it’s least useful.\n",
    "# If the difference is large (positive or negative), removing it changed accuracy a lot → it’s more important.\n",
    "# In this case Industry is least useful.\n",
    "\n",
    "base_acc = accuracy_score(y_val, y_pred)\n",
    "print(\"Base accuracy:\", base_acc)\n",
    "\n",
    "feature_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "diffs = {}\n",
    "\n",
    "for f in feature_to_test:\n",
    "    X_train_sub = X_train.drop(columns=[f])\n",
    "    X_val_sub = X_val.drop(columns=[f])\n",
    "\n",
    "    dv_sub = DictVectorizer(sparse=False)\n",
    "    X_train_enc_sub = dv_sub.fit_transform(X_train_sub.to_dict(orient='records'))\n",
    "    X_val_enc_sub = dv_sub.transform(X_val_sub.to_dict(orient='records'))\n",
    "\n",
    "    model_sub = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_sub.fit(X_train_enc_sub, y_train)\n",
    "    acc_sub = accuracy_score(y_val, model_sub.predict(X_val_enc_sub))\n",
    "    diffs[f] = base_acc - acc_sub\n",
    "\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c4fab22-75c3-4e7c-8af6-d301438ad658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: 0.700\n",
      "C=0.1: 0.700\n",
      "C=1: 0.700\n",
      "C=10: 0.700\n",
      "C=100: 0.700\n"
     ]
    }
   ],
   "source": [
    "# Question 6. Now let's train a regularized logistic regression.\n",
    "# Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100]. Train models using all the features as in Q4.\n",
    "# Calculate the accuracy on the validation dataset and round it to 3 decimal digits. Which of these C leads to the best accuracy on the validation set?\n",
    "\n",
    "# We remember our original accuracy.Then, one by one, we remove a feature and retrain. We see how much accuracy drops.The one with the smallest drop \n",
    "# is least useful.\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    acc = accuracy_score(y_val, model.predict(X_val_encoded))\n",
    "    print(f\"C={C}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f68d7-711d-4b6c-b5d3-c4ecb501c440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
