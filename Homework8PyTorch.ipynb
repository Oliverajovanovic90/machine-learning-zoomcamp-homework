{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325f351b-78c2-426a-83d9-6808fc52d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports & seed initialized!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- Seed for reproducibility ---\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"✅ Imports & seed initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c3387e-8c31-4741-94e4-53caadea1a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.zip downloaded: True\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset file exists after download\n",
    "print(\"data.zip downloaded:\", os.path.exists(\"data.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e87ca3-bb13-45cf-a11c-f5409108dcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset extracted!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"data.zip\", \"r\") as z:\n",
    "    z.extractall(\".\")  # extract in workspace root\n",
    "\n",
    "print(\"✅ Dataset extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1b2532-d2ce-498a-8909-215a3110a524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir exists: False\n",
      "Test dir exists: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dir exists:\", os.path.exists(\"train\"))\n",
    "print(\"Test dir exists:\", os.path.exists(\"test\"))\n",
    "\n",
    "# See example files\n",
    "if os.path.exists(\"train\"):\n",
    "    print(\"\\nSample train folder content:\", os.listdir(\"train\")[:5])\n",
    "if os.path.exists(\"test\"):\n",
    "    print(\"Sample test folder content:\", os.listdir(\"test\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4bf37-7848-4deb-ac77-01aa7e0e5e10",
   "metadata": {},
   "source": [
    "datasets → loads image datasets\n",
    "\n",
    "transforms → prepares images (resize, convert to tensor, normalize)\n",
    "\n",
    "DataLoader → feeds images to the model in batches\n",
    "\n",
    "Set test_transforms = train_transforms → meaning both train and test images get the same preparation. \n",
    "    \n",
    "Dataset loading - Reads images from those folders. Automatically assigns labels based on folder names (curly, straight). Applies the transforms above.\n",
    "\n",
    "Creating loaders - 20 images at a time go into model (batch_size=20), shuffle=True on train → random order each epoch (good for training)\n",
    "shuffle=False on test → fixed order (correct, required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a083bcd0-1662-4cce-9ab4-960f36e1a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataLoaders created!\n",
      "Classes detected: ['curly', 'straight']\n",
      "Number of train images: 800\n",
      "Number of test images: 201\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Image transformations required by homework\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transforms = train_transforms  # same transforms, no extra preprocessing needed\n",
    "\n",
    "# Load dataset from extracted folder\n",
    "train_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(\"data/test\", transform=test_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "print(\"✅ DataLoaders created!\")\n",
    "print(\"Classes detected:\", train_dataset.classes)\n",
    "print(\"Number of train images:\", len(train_dataset))\n",
    "print(\"Number of test images:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6a621f-9465-4ea9-a5fd-4089434e89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5103f416-1103-4ac1-83f6-373ec1e3d224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CNN model initialized!\n",
      "Total parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class HairTypeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # First conv layer: input channel 3 (RGB), output channel 32, kernel 3×3\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "\n",
    "        # After conv + pool, we flatten and pass to linear layer with 64 neurons\n",
    "        self.fc1 = nn.Linear(32 * 99 * 99, 64)  # 99*99 comes after 3×3 conv with no padding + 2×2 pool\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Final output layer for binary classification (1 neuron)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # activation for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv(x)))\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.relu2(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = HairTypeCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"✅ CNN model initialized!\")\n",
    "print(\"Total parameters:\", sum(p.numel() for p in model.parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb38bd3-6eb1-49e4-8933-8deac7072ece",
   "metadata": {},
   "source": [
    "A CNN learns images by scanning with filters, extracting strong patterns, shrinking the data, flattening it into numbers, \n",
    "and using linear layers to learn how patterns map to a yes/no decision — in this case, curly vs straight hair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0a3cf-8278-46a6-a5be-45eeba3582c2",
   "metadata": {},
   "source": [
    "1. nn.BCEWithLogitsLoss()\n",
    "2. Total parameters: 20073473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f1fde9-5223-41e9-966c-6309717b1150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation DataLoader created!\n",
      "Validation images: 201\n"
     ]
    }
   ],
   "source": [
    "# Validation transformations (same as train/test for consistency)\n",
    "val_transforms = train_transforms\n",
    "\n",
    "# Load validation dataset (if you want a separate validation split, we can create one slowly after)\n",
    "validation_dataset = datasets.ImageFolder(\"data/test\", transform=val_transforms)\n",
    "\n",
    "# Create DataLoader for validation\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "print(\"✅ Validation DataLoader created!\")\n",
    "print(\"Validation images:\", len(validation_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236af4da-05d1-4f69-96b0-0c85c87bee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6736, Acc: 0.4875\n",
      "Epoch 2/10, Loss: 0.6541, Acc: 0.4875\n",
      "Epoch 3/10, Loss: 0.6376, Acc: 0.4875\n",
      "Epoch 4/10, Loss: 0.6345, Acc: 0.4875\n",
      "Epoch 5/10, Loss: 0.6220, Acc: 0.4875\n",
      "Epoch 6/10, Loss: 0.6177, Acc: 0.4875\n",
      "Epoch 7/10, Loss: 0.6130, Acc: 0.4875\n",
      "Epoch 8/10, Loss: 0.6087, Acc: 0.4875\n",
      "Epoch 9/10, Loss: 0.6044, Acc: 0.4875\n",
      "Epoch 10/10, Loss: 0.5948, Acc: 0.4875\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cebde31a-ea5f-44ea-86c5-edb53e3f2848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy history: [0.4875, 0.4875, 0.4875, 0.4875, 0.4875, 0.4875, 0.4875, 0.4875, 0.4875, 0.4875]\n",
      "Loss history: [0.6736191228032112, 0.654145672917366, 0.6376249462366104, 0.6345452621579171, 0.622015492618084, 0.6177252188324929, 0.6130436688661576, 0.6086574584245682, 0.6043648511171341, 0.5948178455233574]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy history:\", history['acc'])\n",
    "print(\"Loss history:\", history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b4364-9d48-4708-994e-b7afbf6737ac",
   "metadata": {},
   "source": [
    "median is 0.4875\n",
    "std 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ddedd22-6250-41ee-b9de-3c109876c0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median training accuracy: 0.4875\n",
      "Std of training loss: 0.022937467873778965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Question 3: median training accuracy ---\n",
    "median_acc = float(np.median(history['acc']))\n",
    "print(\"Median training accuracy:\", median_acc)\n",
    "\n",
    "# --- Question 4: standard deviation of training loss ---\n",
    "std_loss = float(np.std(history['loss']))\n",
    "print(\"Std of training loss:\", std_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1acb7f8-8597-49fe-8966-5b53c5d8d2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train transforms updated with augmentation!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Updated train transforms with augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"✅ Train transforms updated with augmentation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacbdc03-2160-4aef-98f8-54275fcea3d9",
   "metadata": {},
   "source": [
    "What this does\n",
    "Still resizes to 200×200\n",
    "Adds:\n",
    "Random rotations\n",
    "Random crops (slight zoom in/out)\n",
    "Horizontal flips (mirror)\n",
    "Keeps normalization and tensor conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4882916-7b1f-4faf-b3df-d23eac83593f",
   "metadata": {},
   "source": [
    "load only the training data again with the new transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1065c5b-aee4-48e5-995d-42abeb30e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training dataset and loader updated with augmentations!\n",
      "Total train images: 800\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Reload only training dataset with augmentations\n",
    "train_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\n",
    "\n",
    "# Recreate DataLoader to use updated transforms\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "print(\"✅ Training dataset and loader updated with augmentations!\")\n",
    "print(\"Total train images:\", len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42f2cdf-3ddf-4d35-aff4-fa116e17bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (Augmented),  Test Loss: 0.6560, Test Acc: 0.4975\n",
      "Epoch 2/10 (Augmented),  Test Loss: 0.6564, Test Acc: 0.5075\n",
      "Epoch 3/10 (Augmented),  Test Loss: 0.6529, Test Acc: 0.5373\n",
      "Epoch 4/10 (Augmented),  Test Loss: 0.6535, Test Acc: 0.5124\n",
      "Epoch 5/10 (Augmented),  Test Loss: 0.6493, Test Acc: 0.5124\n",
      "Epoch 6/10 (Augmented),  Test Loss: 0.6489, Test Acc: 0.5174\n",
      "Epoch 7/10 (Augmented),  Test Loss: 0.6485, Test Acc: 0.5522\n",
      "Epoch 8/10 (Augmented),  Test Loss: 0.6493, Test Acc: 0.5274\n",
      "Epoch 9/10 (Augmented),  Test Loss: 0.6522, Test Acc: 0.5224\n",
      "Epoch 10/10 (Augmented),  Test Loss: 0.6548, Test Acc: 0.5473\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # 10 more epochs\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_running_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_test_loss = test_running_loss / test_total\n",
    "    epoch_test_acc = test_correct / test_total\n",
    "\n",
    "    test_loss_history.append(epoch_test_loss)\n",
    "    test_acc_history.append(epoch_test_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/10 (Augmented), \",\n",
    "          f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdd99d87-a1c5-4b6b-b71d-a8315575d26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 → Mean of test loss: 0.65218\n",
      "Q6 → Avg test accuracy for last 5 epochs: 0.5333399999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Results your training already produced (Augmented test performance)\n",
    "test_loss_history = [\n",
    "    0.6560, 0.6564, 0.6529, 0.6535, 0.6493,\n",
    "    0.6489, 0.6485, 0.6493, 0.6522, 0.6548\n",
    "]\n",
    "\n",
    "test_acc_history = [\n",
    "    0.4975, 0.5075, 0.5373, 0.5124, 0.5124,\n",
    "    0.5174, 0.5522, 0.5274, 0.5224, 0.5473\n",
    "]\n",
    "\n",
    "# --- Question 5: Mean Test Loss ---\n",
    "mean_test_loss = float(np.mean(test_loss_history))\n",
    "print(\"Q5 → Mean of test loss:\", mean_test_loss)\n",
    "\n",
    "# --- Question 6: Avg Test Accuracy for Last 5 Epochs (6–10) ---\n",
    "last_5_test_acc = test_acc_history[5:]  # epochs 6-10\n",
    "avg_last_5_test_acc = float(np.mean(last_5_test_acc))\n",
    "print(\"Q6 → Avg test accuracy for last 5 epochs:\", avg_last_5_test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c878f-24c7-47f6-9c72-b5545469ca33",
   "metadata": {},
   "source": [
    "This model performs slightly better after augmentations, but still near-random accuracy (~53%), \n",
    "so improvement exists but needs more epochs/architecture work in future to match top submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c02d7c-5a8a-439e-be3b-de6e7ebee643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
